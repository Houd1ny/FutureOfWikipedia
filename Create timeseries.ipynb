{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from urllib.parse import quote, urlencode\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"https://uk.wikipedia.org/w/api.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getViews(page, start, end, project='uk.wikipedia'):\n",
    "    \"\"\"\n",
    "    Get number of Views for certain page for every day between start and end. \n",
    "    params: page: which pages you want data for\n",
    "    params: start: starting from this date\n",
    "    params: end: end on this date\n",
    "    params: project: which wiki\n",
    "    return: df: created dataframe with timeseries\n",
    "    \n",
    "    \"\"\"\n",
    "    base_url = \"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/%s/all-access/all-agents/%s/daily/%s/%s\" % (project,page,start,end)\n",
    "    data = urllib.request.urlopen(base_url)\n",
    "    dataJson = json.loads(data.read().decode('utf-8'))['items']\n",
    "    df = pd.DataFrame(dataJson) [['views','timestamp']]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y%m%d%H')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRevisions_andAge(pageTitle, timestamp):\n",
    "    \"\"\"\n",
    "    Get number of Revisions for certain day \n",
    "    params: pageTitle: which pages you want data for\n",
    "    params: timestamp: on which date\n",
    "    return: users: all user revisions\n",
    "    return: delta.days: age of page in days (from first revision till timestamp)\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    params[\"action\"] = \"query\"\n",
    "    params[\"format\"] = \"json\"\n",
    "    params[\"prop\"] = \"revisions\"\n",
    "    params[\"rvlimit\"] = \"1000\"\n",
    "    params[\"rvstart\"] = timestamp #It goes down (new on top)\n",
    "    users = []\n",
    "    revs = []\n",
    "    \n",
    "    while True:\n",
    "        response = urllib.request.urlopen(HOST + \"?\" + urlencode(params) + \"&titles=\" + quote(pageTitle)).read().decode('utf-8')\n",
    "        dataJson = json.loads(response)\n",
    "        pages = dataJson[\"query\"][\"pages\"]\n",
    "        key = list(pages.keys())[0]\n",
    "        revisions = pages[key]['revisions']\n",
    "        users = users + [rev[\"user\"] for rev in revisions]\n",
    "        revs = revs + [rev for rev in revisions]\n",
    "        \n",
    "        if \"continue\" in dataJson.keys():\n",
    "            cont = dataJson[\"continue\"][\"rvcontinue\"]\n",
    "            params[\"rvcontinue\"] = cont\n",
    "        else:\n",
    "            break\n",
    "    last_revision = revs[-1]\n",
    "    page_born = datetime.datetime.strptime(last_revision['timestamp'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "    timestamp_datetime = datetime.datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    # today = datetime.datetime.today()\n",
    "    delta = timestamp_datetime - page_born\n",
    "    return users, delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries(page_titles, str_date_from, number_of_days):\n",
    "    \"\"\"\n",
    "    Create timeseries start from given date and go older\n",
    "    params: page_titles: which pages you want data for\n",
    "    params: str_date_from: this and number_of_days before will be taken\n",
    "    params: number_of_days: how many days back from start should we look\n",
    "    return: df: created dataframe with timeseries\n",
    "    \"\"\"\n",
    "    datetime_start = datetime.datetime.strptime(str_date_from, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    df = pd.DataFrame(columns=['timestamp','page_name','revisions_count','contributors_count','age_of_page_days'])\n",
    "    for i in range(number_of_days):\n",
    "        time_query  = datetime_start - datetime.timedelta(days=i)\n",
    "        time_query_revs_str = time_query.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        time_query_views_str = time_query.strftime(\"%Y%m%d00\")\n",
    "        print(time_query_revs_str)\n",
    "        \n",
    "        print(\"Run for {}, when took {} days back\".format(time_query_revs_str, i))\n",
    "        for page_name in page_titles:\n",
    "            try:\n",
    "                users_updated, age_of_page_days = GetRevisions_andAge(page_name,time_query_revs_str)\n",
    "                revisions = len(users_updated)\n",
    "                contributors = len(set(users_updated))\n",
    "                try:\n",
    "                    num_of_views = getViews(page_name,time_query_views_str,time_query_views_str) \n",
    "                except:\n",
    "                    num_of_views = 0\n",
    "                df = df.append({'timestamp':time_query_revs_str,\n",
    "                            'page_name':page_name,\n",
    "                            'revisions_count':revisions,\n",
    "                            'contributors_count':contributors,\n",
    "                            'age_of_page_days':age_of_page_days,\n",
    "                            'num_of_views':num_of_views\n",
    "                            }, ignore_index=True)\n",
    "            except  Exception as e:\n",
    "                print(\"Error for page {} on {} day before\".format(page_name, i))\n",
    "                print(\"Error message: {}\".format(e))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SUBSET = 100\n",
    "DAYS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-07T12:00:00Z\n",
      "Run for 2018-06-07T12:00:00Z, when took 0 days back\n"
     ]
    }
   ],
   "source": [
    "#Load Yurii data\n",
    "\n",
    "pkl_file = open('pages.pkl', 'rb')\n",
    "data1 = pickle.load(pkl_file)\n",
    "\n",
    "titles = [i[0].replace(\" \", \"_\") for i in data1] # only Ukr titles\n",
    "#titles = titles[-TEST_SUBSET:]\n",
    "my_df = create_timeseries(titles, \"2018-06-07T12:00:00Z\", DAYS)\n",
    "my_df.to_csv('{}days{}pages.csv'.format(DAYS,TEST_SUBSET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/kzorina/Studing/MMDS/not_eng_titles_500.csv\")\n",
    "titles = df['uk_title'].tolist()\n",
    "titles = [i.replace(\" \", \"_\") for i in titles]\n",
    "№titles = titles[50:150]\n",
    "not_eng_df = create_timeseries(titles, \"2018-06-07T12:00:00Z\", DAYS)\n",
    "not_eng_df.to_csv('Not_translated{}days{}pages.csv'.format(DAYS,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demo how function works\n",
    "users_updated, age_of_page_days = GetRevisions(\"Львів\",\"2018-01-15T14:56:00Z\")\n",
    "revisions = len(users_updated)\n",
    "contributors = len(set(users_updated))\n",
    "\n",
    "print(\"Revisions: \".format(revisions))\n",
    "print(\"contributors\".format(contributors))\n",
    "print(\"Age of page\".format(age_of_page_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In development....\n",
    "def get_lang():\n",
    "    \"\"\"\n",
    "    For every title find its translations (among 10 lang for now)\n",
    "    + get their first revision\n",
    "    \"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
